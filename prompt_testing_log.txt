Try 0:
    prompt = "Are any medical symptoms mentioned in the transcript"

    --> No structured output, but correct answer. The answer seems to start with Yes or No.
    ==> We can use the first word of the answer as the output itself. (limit: will not scale to multilabel prompting).

    Results:
        accuracy: 0.737 (0.7-0.7727 95% CI)
        precision: 0.7245 (0.6856-0.7614 95% CI)
        recall: 1.0 (1.0-1.0 95% CI)
        f1: 0.8401 (0.8135-0.8645 95% CI)
        Unstructured output ratio: 0.0 (0.0-0.0 95% CI)
        Total tokens: 389,372

    Analysis:
        There are no unstructured outputs: the output always starts with Yes or No.
        For the next iteration, we don't need to focus on structuring the output, but rather on the quality of the answer.


Try 1:
    prompt = "You are a model diagnosing diseases based on Doctor - Patient conversations. \
              Given a conversation, you should determine whether the patient has symptoms or not. \
              Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.8017 (0.7631-0.8384 95% CI)
        precision: 0.7935 (0.7547-0.8313 95% CI)
        recall: 1.0 (1.0-1.0 95% CI)
        f1: 0.8847 (0.8602-0.9079 95% CI)
        Unstructured output ratio: 0.213 (0.18-0.2473 95% CI)
        Total tokens: 416,396

    Analysis:
        Providing more context to the model improved the performance.
        This prompt also leads to a higher unstructured output ratio. All the unstructured outputs start with
            "Based on the conversation provided, ...".
        For the next iteration, we can make an explicit statement that the model should not provide any context, and that the
            answer should be a simple Yes or No.


Try 2:
    prompt = "You are a model diagnosing diseases based on Doctor - Patient conversations. \
              Given a conversation, you should determine whether the patient has symptoms or not. \
              Your answer should not provide any context, it should be a simple Yes or No.\
              Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.7465 (0.7127-0.78 95% CI)
        precision: 0.7387 (0.7031-0.7771 95% CI)
        recall: 0.979 (0.9631-0.9921 95% CI)
        f1: 0.8419 (0.8174-0.8666 95% CI)
        Unstructured output ratio: 0.0 (0.0-0.0 95% CI)
        Total tokens: 186,786

    Analysis:
        The model now generates structured outputs. Because of that, the number of tokens used is significantly lower.
        However, the performance is worse than the previous try.
        We can see that the model's errors are mostly false positives. To improve on this, we can perform error interrogation
            to understand the types of error.

        Type 1: Symptoms relative to other people
            Context: "P: Uhm, I know my grandfather had lung cancer, but he used to smoke. D: OK, I see. How old was he? [...]"
            Output: "Yes, the patient mentions that their grandfather had lung cancer, which is a medical symptom. [...]"
            --> To fix this, we could introduce such an example in the prompt and explictly tell the model that it should not
                consider symptoms that are not related to the patient.

        Type 2: Symptoms could be inferred from the context, but not explicit
            Context: "D: Yeah, and no worries, and then we'll also do like a full physical examination. P: That sounds great. D: Alright."
            Model Output: "Yes, the patient mentions "a full physical examination" which implies that they are experiencing some symptoms [...]"
            --> Similarly, this can be fixed by providing an example in the prompt and explicitly telling the model that it should
                only consider explicit mentions of symptoms. We could pass the list of allowed symptoms in the prompt.


Try 3:
    prompt = "You are a model diagnosing diseases based on Doctor - Patient conversations. \
              Given a conversation, you should determine whether the patient has symptoms or not. \
              Your answer should not provide any context, it should be a simple Yes or No. \
              Some symptoms will be mentioned but will not apply to the patient. It is important \
              that you only consider symptoms that are experienced by the patient. It is also \
              important that you only consider explicit mentions of symptoms. \
              Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.7543 (0.7164-0.7909 95% CI)
        precision: 0.7376 (0.6996-0.7758 95% CI)
        recall: 1.0 (1.0-1.0 95% CI)
        f1: 0.8488 (0.8233-0.8738 95% CI)
        Unstructured output ratio: 0.0 (0.0-0.0 95% CI)
        Total tokens: 212,830
        
    Analysis:
        There does not appear to be a statisically significant difference between this try and the previous one.
        To improve on the two types of errors, we can provide few shot examples of false positives in the prompt.
        Based on the following paper: https://arxiv.org/abs/2201.11903, adding chain-of-thought examples could improve the
            model's performance. We can explain the thought process with the examples in the prompt.


Try 4:
    prompt = "You are a model diagnosing diseases based on Doctor - Patient conversations. \
              Given a conversation, you should determine whether the patient has symptoms or not. \
              Your answer should not provide any context, it should be a simple Yes or No. \
              Some symptoms will be mentioned but will not apply to the patient. It is important \
              that you only consider symptoms that are experienced by the patient. \
              An example of a patient mentioning a symptom that does not apply to them is: \
              'P: My daughter is having fevers and barely sleeps'. Your answer should be \
              'No, since the patient is not the one experiencing the symptoms,'. \
              It is also important that you only consider explicit mentions of symptoms. \
              An example of a patient not explicitly mentioning a symptom is: \
              'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
              Your answer should be: 'No, although the patient needs to get an MRI which \
              implies that they are experiencing some symptoms, they do not explicitly mention any.' \
              Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.7942 (0.7582-0.8291 95% CI)
        precision: 0.7727 (0.7337-0.8099 95% CI)
        recall: 0.9946 (0.9865-1.0 95% CI)
        f1: 0.8696 (0.8452-0.8937 95% CI)
        Unstructured output ratio: 0.0 (0.0-0.0 95% CI)
        Total tokens: 288,502

    Analysis:
        While introducing examples has helped improve the performance, we are still not on par with the performance of try 1.
        The drop in performance occurred between try 1 and try 2, as we gave specific instructions to the model to structure its output.
        To confirm that this is what changed the performance, we can keep the same prompt, but remove the instructions relative to output structure.


Try 5:
    prompt = "You are a model diagnosing diseases based on Doctor - Patient conversations. \
              Given a conversation, you should determine whether the patient has symptoms or not. \
              Some symptoms will be mentioned but will not apply to the patient. It is important \
              that you only consider symptoms that are experienced by the patient. \
              An example of a patient mentioning a symptom that does not apply to them is: \
              'P: My daughter is having fevers and barely sleeps'. Your answer should be \
              'No, since the patient is not the one experiencing the symptoms,'. \
              It is also important that you only consider explicit mentions of symptoms. \
              An example of a patient not explicitly mentioning a symptom is: \
              'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
              Your answer should be: 'No, although the patient needs to get an MRI which \
              implies that they are experiencing some symptoms, they do not explicitly mention any.' \
              Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.8146 (0.7828-0.8462 95% CI)
        precision: 0.7928 (0.7554-0.8285 95% CI)
        recall: 0.9921 (0.982-1.0 95% CI)
        f1: 0.8812 (0.8575-0.9043 95% CI)
        Unstructured output ratio: 0.0036 (0.0-0.0091 95% CI)
        Total tokens: 311,819

    Analysis:
        The performance is now on par with the performance of try 1, while having a lower unstructured output ratio.
        This confirms that the drop in performance between try 1 and try 2 was due to the instructions given to the model to structure its output.
        We can move forward with this prompt and focus on improving the precision, as the recall is already very high.


Try 6:
    --> While the prompts implemented chain of thought examples, they did not respect the model's expected output format.
        We can try to implement the chain of thought examples while respecting the expected output format.

    prompt = "You are a helpful model diagnosing diseases based on Doctor - Patient conversations. \
            Given a conversation, you should determine whether the patient has symptoms or not. \
            Some symptoms will be mentioned but will not apply to the patient. It is important \
            that you only consider symptoms that are experienced by the patient. \
            An example of a patient mentioning a symptom that does not apply to them is: \
            'P: My daughter is having fevers and barely sleeps'. Your answer should be \
            'No'. This is due to the fact that the patient is not the one experiencing the symptoms. \
            It is also important that you only consider explicit mentions of symptoms. \
            An example of a patient not explicitly mentioning a symptom is: \
            'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
            Your answer should be: 'No'. This is because the patient needs to get an MRI which \
            implies that they are experiencing some symptoms, they do not explicitly mention any.'\
            Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.7973 (0.7625-0.8318 95% CI)
        precision: 0.7775 (0.7413-0.815 95% CI)
        recall: 0.9946 (0.9864-1.0 95% CI)
        f1: 0.8726 (0.8476-0.8961 95% CI)
        Unstructured output ratio: 0.0109 (0.0036-0.0218 95% CI)
        Total tokens: 319,653

    Analysis:
        The performance is similar to the previous try. The unstructured output ratio is higher, but still low.
        We can aim to simplify the prompt by keeping the examples, but removing the chain of though examples.

    
Try 7:
    prompt = "You are a helpful model diagnosing diseases based on Doctor - Patient conversations. \
            Given a conversation, you should determine whether the patient has symptoms or not. \
            Some symptoms will be mentioned but will not apply to the patient. It is important \
            that you only consider symptoms that are experienced by the patient. \
            An example of a patient mentioning a symptom that does not apply to them is: \
            'P: My daughter is having fevers and barely sleeps'. Your answer should be \
            'No'. It is also important that you only consider explicit mentions of symptoms. \
            An example of a patient not explicitly mentioning a symptom is: \
            'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
            Your answer should be: 'No'. \
            Are any medical symptoms mentioned in the transcript?"
    
    Results:
        accuracy: 0.8366 (0.8055-0.8668 95% CI)
        precision: 0.8152 (0.7797-0.8502 95% CI)
        recall: 0.9893 (0.9786-0.9974 95% CI)
        f1: 0.8937 (0.8708-0.9156 95% CI)
        Unstructured output ratio: 0.0074 (0.0018-0.0164 95% CI)
        Total tokens: 281,995

    Analysis:
        Simplifying the prompt helped improve the performance. This is the best performing prompt so far.
        We can try to bias the model in reducing false positives by explicitly mentioning that it should
            be conservative in its predictions.


Try 8:
    prompt = "You are a helpful model diagnosing diseases based on Doctor - Patient conversations. \
            Given a conversation, you should determine whether the patient has symptoms or not. \
            Some symptoms will be mentioned but will not apply to the patient. It is important \
            that you only consider symptoms that are experienced by the patient. \
            An example of a patient mentioning a symptom that does not apply to them is: \
            'P: My daughter is having fevers and barely sleeps'. Your answer should be \
            'No'. It is also important that you only consider explicit mentions of symptoms. \
            An example of a patient not explicitly mentioning a symptom is: \
            'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
            Your answer should be: 'No'. \
            You should refrain from answering yes if you are not certain. If you are not \
            certain, your answer should be: 'No'. \
            Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.864 (0.8353-0.892 95% CI)
        precision: 0.8519 (0.8184-0.8834 95% CI)
        recall: 0.9805 (0.9638-0.9922 95% CI)
        f1: 0.9116 (0.8909-0.9307 95% CI)
        Unstructured output ratio: 0.0817 (0.06-0.1055 95% CI)
        Total tokens: 392,771

    Analysis:
        The overall performance has increased. Accuracy and Precision increased by about 3 and 4 points respectively.
        Interestingly, while we ask the model to be more conservative (which helps with the false positives), the number
            of false negatives has not increased.
        In order to help the model define the scope of what a medical symptom is, we can pass it the list of symptoms
            from the multilabel classification task. This will help the model understand what it should be looking for.


Try 9:
    prompt = "You are a helpful model diagnosing diseases based on Doctor - Patient conversations. \
            Given a conversation, you should determine whether the patient has symptoms or not. \
            Some symptoms will be mentioned but will not apply to the patient. It is important \
            that you only consider symptoms that are experienced by the patient. \
            An example of a patient mentioning a symptom that does not apply to them is: \
            'P: My daughter is having fevers and barely sleeps'. Your answer should be \
            'No'. It is also important that you only consider explicit mentions of symptoms. \
            An example of a patient not explicitly mentioning a symptom is: \
            'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
            Your answer should be: 'No'. \
            You should refrain from answering yes if you are not certain. If you are not \
            certain, your answer should be: 'No'. \
            Here is the list of possible symptoms: \
            ['anxiety', 'concentration problems', 'constipation', 'cough', \
                    'diarrhea', 'fatigue', 'fever', 'headache', 'nausea', \
                    'numbness and tingling', 'pain', 'poor appetite', 'rash', \
                    'shortness of breath', 'trouble drinking fluids', 'vomiting', 'other'] \
            Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.9151 (0.8865-0.9407 95% CI)
        precision: 0.9142 (0.8811-0.9434 95% CI)
        recall: 0.9784 (0.9606-0.9931 95% CI)
        f1: 0.9451 (0.9255-0.962 95% CI)
        Unstructured output ratio: 0.3145 (0.2764-0.3545 95% CI)
        Total tokens: 805,758

    Results:
        There is a significant increase for all the metrics (apart for the recall which was already high).
        However, this comes at the expense of a much higher unstructured output ratio.
        We can iterate on this prompt to reduce the unstructured output ratio.
        Adding the list at the end most likely offsets the attention from the examples to the set of
            possible symptoms. We can try to add the list at the beginning of the prompt instead, since
            order matters in prompts.


Try 10:
    prompt = "You are a helpful model diagnosing diseases based on Doctor - Patient conversations. \
            Given a conversation, you should determine whether the patient has symptoms or not. \
            Here is the list of possible symptoms: \
            ['anxiety', 'concentration problems', 'constipation', 'cough', \
                    'diarrhea', 'fatigue', 'fever', 'headache', 'nausea', \
                    'numbness and tingling', 'pain', 'poor appetite', 'rash', \
                    'shortness of breath', 'trouble drinking fluids', 'vomiting', 'other'] \
            Some symptoms will be mentioned but will not apply to the patient. It is important \
            that you only consider symptoms that are experienced by the patient. \
            An example of a patient mentioning a symptom that does not apply to them is: \
            'P: My daughter is having fevers and barely sleeps'. Your answer should be \
            'No'. It is also important that you only consider explicit mentions of symptoms. \
            An example of a patient not explicitly mentioning a symptom is: \
            'D: You need to get an MRI as soon as possible. P: OK. D: Alright.' \
            Your answer should be: 'No'. \
            You should refrain from answering yes if you are not certain. If you are not \
            certain, your answer should be: 'No'. \
            Are any medical symptoms mentioned in the transcript?"

    Results:
        accuracy: 0.8736 (0.8434-0.903 95% CI)
        precision: 0.8647 (0.8298-0.8992 95% CI)
        recall: 0.9825 (0.9665-0.9943 95% CI)
        f1: 0.9198 (0.8986-0.9397 95% CI)
        Unstructured output ratio: 0.1678 (0.1382-0.1964 95% CI)
        Total tokens: 593,737

    Analysis:
        Interestingly, moving the list of symptoms to the beginning of the prompt has reduced the
            unstructured output ratio and the performance. After trying several approaches, it seems
            difficult to keep the performance high while reducing the unstructured output ratio.
        We therefore select prompt 8 as the best performing prompt, as it has the best performance
            while keeping the unstructured output ratio low.